{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ПРОВЕРКА УСТАНОВКИ PYTORCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Проверка памяти GPU\n",
    "    print(f\"GPU memory total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"Device: {device} (CUDA не доступна!)\")\n",
    "\n",
    "print(\"=\" * 60)"
   ],
   "id": "2915b092a48504b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Проверка GPU\n",
    "print(\"=\" * 60)\n",
    "print(\"ИНФОРМАЦИЯ О СИСТЕМЕ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Используется CPU\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создаем более сложную модель для демонстрации\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Загружаем данные\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Скачиваем MNIST\n",
    "print(\"Загрузка данных MNIST...\")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Создаем DataLoader с учетом GPU\n",
    "batch_size = 128  # Можете увеличить, т.к. у вас 16GB памяти\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Размер батча: {batch_size}\")\n",
    "print(f\"Обучающих примеров: {len(train_dataset)}\")\n",
    "print(f\"Тестовых примеров: {len(test_dataset)}\")\n",
    "\n",
    "# Создаем модель и перемещаем на GPU\n",
    "model = CNNModel().to(device)\n",
    "print(f\"\\nМодель создана и перемещена на {device}\")\n",
    "\n",
    "# Функция для подсчета параметров\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Количество обучаемых параметров: {count_parameters(model):,}\")\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функция обучения\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Перемещаем данные на GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'  Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Функция валидации\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Обучение модели\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"НАЧАЛО ОБУЧЕНИЯ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "epochs = 5\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nЭпоха {epoch+1}/{epochs}')\n",
    "\n",
    "    # Обучение\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Валидация\n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Показываем использование памяти GPU\n",
    "    if torch.cuda.is_available():\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f'  GPU Memory - Allocated: {memory_allocated:.2f} GB, Reserved: {memory_reserved:.2f} GB')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ОБУЧЕНИЕ ЗАВЕРШЕНО\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Визуализация результатов\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(range(1, epochs+1), train_losses, 'b-', label='Train Loss')\n",
    "ax1.plot(range(1, epochs+1), val_losses, 'r-', label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss over epochs')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(range(1, epochs+1), train_accs, 'b-', label='Train Accuracy')\n",
    "ax2.plot(range(1, epochs+1), val_accs, 'r-', label='Val Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy over epochs')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Тестирование на нескольких примерах\n",
    "print(\"\\nТестирование на нескольких примерах:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Берем несколько примеров из тестового набора\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data[:8].to(device), target[:8].to(device)\n",
    "    output = model(data)\n",
    "    _, predicted = output.max(1)\n",
    "\n",
    "    # Перемещаем обратно на CPU для отображения\n",
    "    data = data.cpu()\n",
    "    predicted = predicted.cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    # Показываем изображения и предсказания\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < 8:\n",
    "            image = data[idx].squeeze().numpy()\n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(f'Pred: {predicted[idx]}, True: {target[idx]}')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Финальная статистика\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ФИНАЛЬНАЯ СТАТИСТИКА\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Финальная точность на валидации: {val_accs[-1]:.2f}%\")\n",
    "print(f\"Финальная потеря на валидации: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# Сохранение модели\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_accs': val_accs,\n",
    "}, 'mnist_cnn_model.pth')\n",
    "\n",
    "print(\"Модель сохранена в 'mnist_cnn_model.pth'\")"
   ],
   "id": "849af9995df88430"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Установка устройства\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используется устройство: {device}\")\n",
    "\n",
    "# Исправленная модель для CIFAR-10 (3 канала вместо 1)\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        # Изменяем первый слой на 3 канала (RGB)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Было 1, теперь 3\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Расчет размера после сверток для CIFAR-10 (32x32)\n",
    "        # После conv1 + pool: 32x32 -> 16x16\n",
    "        # После conv2 + pool: 16x16 -> 8x8\n",
    "        # После conv3 + pool: 8x8 -> 4x4\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Загрузка данных CIFAR-10\n",
    "print(\"\\nЗагрузка данных CIFAR-10...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Аугментация\n",
    "    transforms.RandomCrop(32, padding=4),  # Аугментация\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))  # Стандартные значения для CIFAR-10\n",
    "])\n",
    "\n",
    "# Используем CIFAR-10\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Увеличиваем batch size для вашей мощной GPU\n",
    "batch_size = 256  # Можно увеличить до 512 если хватит памяти\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Классы CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Обучающих примеров: {len(train_dataset)}\")\n",
    "print(f\"Тестовых примеров: {len(test_dataset)}\")\n",
    "print(f\"Размер изображений: {train_dataset[0][0].shape}\")\n",
    "\n",
    "# Создаем модель\n",
    "model = EnhancedCNN().to(device)\n",
    "print(f\"\\nМодель создана и перемещена на {device}\")\n",
    "\n",
    "# Функция для подсчета параметров\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Количество обучаемых параметров: {total_params:,}\")\n",
    "\n",
    "# Оптимизатор и функция потерь\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Функция обучения\n",
    "def train_epoch(model, loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Перемещаем данные на GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            accuracy = 100. * correct / total\n",
    "            print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(loader)} | '\n",
    "                  f'Loss: {loss.item():.4f} | Acc: {accuracy:.2f}%')\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Функция валидации\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Обучение модели\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"НАЧАЛО ОБУЧЕНИЯ НА CIFAR-10\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "epochs = 15\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n{\"-\" * 50}')\n",
    "    print(f'Эпоха {epoch+1}/{epochs}')\n",
    "    print(f'{\"-\" * 50}')\n",
    "\n",
    "    # Обучение\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch+1)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Валидация\n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # Обновление learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'\\nИтоги эпохи {epoch+1}:')\n",
    "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "    # Информация о памяти GPU\n",
    "    if torch.cuda.is_available():\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        print(f'  GPU Memory: {memory_allocated:.2f}GB / 16.00GB')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ОБУЧЕНИЕ ЗАВЕРШЕНО\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# График потерь\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, 'b-', linewidth=2, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), val_losses, 'r-', linewidth=2, label='Val Loss')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Loss over epochs', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# График точности\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accs, 'b-', linewidth=2, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), val_accs, 'r-', linewidth=2, label='Val Accuracy')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Accuracy over epochs', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Тестирование на нескольких примерах\n",
    "print(\"\\nТестирование на примерах из тестового набора:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Берем 10 примеров\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data[:10].to(device), target[:10].to(device)\n",
    "    output = model(data)\n",
    "    _, predicted = output.max(1)\n",
    "\n",
    "    # Перемещаем обратно на CPU для отображения\n",
    "    data = data.cpu()\n",
    "    predicted = predicted.cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    # Денормализация изображений\n",
    "    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.2470, 0.2435, 0.2616]).view(3, 1, 1)\n",
    "    data_denorm = data * std + mean\n",
    "    data_denorm = torch.clamp(data_denorm, 0, 1)\n",
    "\n",
    "    # Показываем изображения и предсказания\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < 10:\n",
    "            image = data_denorm[idx].permute(1, 2, 0).numpy()\n",
    "            ax.imshow(image)\n",
    "            title = f'Pred: {classes[predicted[idx]]}\\nTrue: {classes[target[idx]]}'\n",
    "            ax.set_title(title, color='green' if predicted[idx] == target[idx] else 'red')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Предсказания модели на тестовых данных CIFAR-10', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Матрица ошибок\n",
    "print(\"\\nМатрица ошибок (Confusion Matrix):\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, preds = output.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Создаем матрицу ошибок\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Финальная статистика\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ФИНАЛЬНАЯ СТАТИСТИКА\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Финальная точность на валидации: {val_accs[-1]:.2f}%\")\n",
    "print(f\"Финальная потеря на валидации: {val_losses[-1]:.4f}\")\n",
    "print(f\"Лучшая точность на валидации: {max(val_accs):.2f}%\")\n",
    "print(f\"Всего параметров модели: {total_params:,}\")\n",
    "\n",
    "# Сохранение модели\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_accs': val_accs,\n",
    "    'total_params': total_params,\n",
    "}, 'cifar10_enhanced_cnn_corrected.pth')\n",
    "\n",
    "print(\"\\nМодель сохранена в 'cifar10_enhanced_cnn_corrected.pth'\")\n",
    "\n",
    "# Очистка памяти GPU\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Память GPU очищена\")"
   ],
   "id": "e7f13573af76cd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "5b3f82233d6d41bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "3c83bfe4eac41b88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_id = pd.read_csv('selected_images/selected_images_info.csv')\n",
    "df_id['person_id'].value_counts()"
   ],
   "id": "69ad294f658f240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_id = df_id[['filename', 'person_id']]\n",
    "print(df_id.head())\n",
    "print(f\"Всего изображений: {len(df_id)}\")\n",
    "print(f\"Уникальных персон: {df_id['person_id'].nunique()}\")"
   ],
   "id": "524d5adb73a28ab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "img_dir = 'aligned_faces'",
   "id": "83b9854e70f05bf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== КОНФИГУРАЦИЯ ====================\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.identity_df = df_id\n",
    "        self.img_dir = img_dir\n",
    "        self.max_classes = 350\n",
    "        self.min_samples_per_person = 26\n",
    "        self.seed = 42\n",
    "        self.val_ratio = 0.15\n",
    "        self.test_ratio = 0.15\n",
    "        self.batch_size = 128\n",
    "        self.num_workers = 0\n",
    "        self.embedding_size = 512\n",
    "        self.learning_rate = 0.001\n",
    "        self.num_epochs = 25\n",
    "        self.arcface_s = 32.0\n",
    "        self.arcface_m = 0.5\n",
    "\n",
    "# ==================== ОБРАБОТКА ДАННЫХ ====================\n",
    "class CelebADataProcessor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.identity_df = config.identity_df\n",
    "        print(f\"Всего данных: {len(self.identity_df)} изображений\")\n",
    "        print(f\"Уникальных людей: {self.identity_df['person_id'].nunique()}\")\n",
    "\n",
    "    def filter_data(self):\n",
    "        person_counts = self.identity_df['person_id'].value_counts()\n",
    "        top_persons = person_counts.nlargest(self.config.max_classes).index\n",
    "        self.filtered_df = self.identity_df[self.identity_df['person_id'].isin(top_persons)].copy()\n",
    "\n",
    "        unique_ids = sorted(self.filtered_df['person_id'].unique())\n",
    "        self.id_to_idx = {old_id: idx for idx, old_id in enumerate(unique_ids)}\n",
    "        self.idx_to_id = {idx: old_id for old_id, idx in self.id_to_idx.items()}\n",
    "\n",
    "        self.filtered_df['class_idx'] = self.filtered_df['person_id'].map(self.id_to_idx)\n",
    "\n",
    "        print(f\"\\nПосле фильтрации:\")\n",
    "        print(f\"  Всего изображений: {len(self.filtered_df)}\")\n",
    "        print(f\"  Уникальных людей: {self.filtered_df['person_id'].nunique()}\")\n",
    "        print(f\"  Диапазон меток: {self.filtered_df['class_idx'].min()} - {self.filtered_df['class_idx'].max()}\")\n",
    "\n",
    "        return len(unique_ids)\n",
    "\n",
    "    def split_data_by_images(self):\n",
    "        print(f\"\\nРазделение данных по изображениям (стратифицировано)...\")\n",
    "\n",
    "        train_df, temp_df = train_test_split(\n",
    "            self.filtered_df,\n",
    "            test_size=self.config.val_ratio + self.config.test_ratio,\n",
    "            random_state=self.config.seed,\n",
    "            stratify=self.filtered_df['class_idx']\n",
    "        )\n",
    "\n",
    "        val_df, test_df = train_test_split(\n",
    "            temp_df,\n",
    "            test_size=self.config.test_ratio/(self.config.val_ratio + self.config.test_ratio),\n",
    "            random_state=self.config.seed,\n",
    "            stratify=temp_df['class_idx']\n",
    "        )\n",
    "\n",
    "        self.train_df = train_df.reset_index(drop=True)\n",
    "        self.val_df = val_df.reset_index(drop=True)\n",
    "        self.test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "        print(f\"Train: {len(self.train_df)} samples\")\n",
    "        print(f\"Val: {len(self.val_df)} samples\")\n",
    "        print(f\"Test: {len(self.test_df)} samples\")\n",
    "\n",
    "        return {\n",
    "            'train': len(self.train_df),\n",
    "            'val': len(self.val_df),\n",
    "            'test': len(self.test_df),\n",
    "            'num_persons': len(self.filtered_df['person_id'].unique())\n",
    "        }\n",
    "\n",
    "# ==================== ДАТАСЕТ ====================\n",
    "class CelebAClassificationDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = int(row['class_idx'])\n",
    "        return image, label\n",
    "\n",
    "# ==================== МОДЕЛИ ====================\n",
    "class SimpleFaceModel(nn.Module):\n",
    "    \"\"\"Простая и стабильная модель\"\"\"\n",
    "    def __init__(self, num_classes=350, embedding_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        # Используем ResNet18\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Простой embedding слой\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "        # Замораживаем только первые слои\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer1' in name or 'conv1' in name or 'bn1' in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        print(f\"\\nМодель параметров:\")\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"  Всего: {total_params:,}\")\n",
    "        print(f\"  Обучаемых: {trainable_params:,}\")\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        features = self.backbone(x)\n",
    "        embedding = self.embedding(features)\n",
    "\n",
    "        if return_embedding:\n",
    "            return embedding\n",
    "\n",
    "        logits = self.classifier(embedding)\n",
    "        return logits, embedding\n",
    "\n",
    "# ==================== ОСНОВНАЯ ФУНКЦИЯ ====================\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    config = Config()\n",
    "    processor = CelebADataProcessor(config)\n",
    "\n",
    "    num_classes = processor.filter_data()\n",
    "    stats = processor.split_data_by_images()\n",
    "\n",
    "    # Умеренные аугментации\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Датасеты\n",
    "    train_dataset = CelebAClassificationDataset(\n",
    "        processor.train_df, config.img_dir, train_transform\n",
    "    )\n",
    "    val_dataset = CelebAClassificationDataset(\n",
    "        processor.val_df, config.img_dir, val_transform\n",
    "    )\n",
    "    test_dataset = CelebAClassificationDataset(\n",
    "        processor.test_df, config.img_dir, val_transform\n",
    "    )\n",
    "\n",
    "    # Даталоадеры\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size,\n",
    "        shuffle=True, num_workers=config.num_workers\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "\n",
    "    # Создаем модель\n",
    "    model = SimpleFaceModel(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=config.embedding_size\n",
    "    ).to(device)\n",
    "\n",
    "    # Простой оптимизатор\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "\n",
    "    # StepLR scheduler\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "    train_history = {\n",
    "        'loss': [], 'acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    max_patience = 10\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"НАЧАЛО ОБУЧЕНИЯ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # Обучение\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=\"Training\")\n",
    "        for batch_idx, (images, labels) in enumerate(pbar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(images, return_embedding=False)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, predicted = logits.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "            current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{current_acc:.1f}%'\n",
    "            })\n",
    "\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                logits, _ = model(images, return_embedding=False)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = logits.max(1)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                val_total += images.size(0)\n",
    "\n",
    "        val_loss /= val_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "\n",
    "        # Сохраняем историю\n",
    "        train_history['loss'].append(train_loss)\n",
    "        train_history['acc'].append(train_acc)\n",
    "        train_history['val_loss'].append(val_loss)\n",
    "        train_history['val_acc'].append(val_acc)\n",
    "        train_history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f\"\\nИтоги эпохи:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # Сохраняем лучшую модель\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            checkpoint_path = f'checkpoints/best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'val_acc': val_acc,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"  ✓ Сохранена лучшая модель (Acc: {val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  Патience: {patience_counter}/{max_patience}\")\n",
    "\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"  ⚠ Early stopping на эпохе {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Обновляем scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    # ==================== ВИЗУАЛИЗАЦИЯ ====================\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    axes[0, 0].plot(train_history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(train_history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Loss History')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0, 1].plot(train_history['acc'], label='Train Acc', linewidth=2)\n",
    "    axes[0, 1].plot(train_history['val_acc'], label='Val Acc', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].set_title('Accuracy History')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1, 0].plot(train_history['lr'], linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Распределение меток\n",
    "    axes[1, 1].hist(processor.train_df['class_idx'].values, bins=num_classes,\n",
    "                    alpha=0.7, label='Train', density=True)\n",
    "    axes[1, 1].hist(processor.val_df['class_idx'].values, bins=num_classes,\n",
    "                    alpha=0.7, label='Val', density=True)\n",
    "    axes[1, 1].set_xlabel('Class Index')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    axes[1, 1].set_title('Class Distribution')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results_stable.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # ==================== ТЕСТИРОВАНИЕ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ТЕСТИРОВАНИЕ ЛУЧШЕЙ МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Загружаем лучшую модель\n",
    "    checkpoint = torch.load('checkpoints/best_model.pth')\n",
    "    checkpoint = torch.load('checkpoints/best_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits, _ = model(images, return_embedding=False)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = logits.max(1)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "            test_total += images.size(0)\n",
    "\n",
    "    test_loss /= test_total\n",
    "    test_acc = 100. * test_correct / test_total\n",
    "\n",
    "    print(f\"\\nРезультаты на тестовой выборке:\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Correct/Total: {test_correct}/{test_total}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ОБУЧЕНИЕ ЗАВЕРШЕНО!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Лучшая точность на валидации: {best_val_acc:.2f}%\")\n",
    "    print(f\"Точность на тесте: {test_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "77c81d5dd4bcd505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== КОНФИГУРАЦИЯ ====================\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.identity_df = df_id\n",
    "        self.img_dir = img_dir\n",
    "        self.max_classes = 350\n",
    "        self.min_samples_per_person = 26\n",
    "        self.seed = 42\n",
    "        self.val_ratio = 0.15\n",
    "        self.test_ratio = 0.15\n",
    "        self.batch_size = 64\n",
    "        self.num_workers = 0\n",
    "        self.embedding_size = 512\n",
    "        self.learning_rate = 0.0001\n",
    "        self.num_epochs_ce = 25  # Эпох для CE\n",
    "        self.num_epochs_arcface = 15  # Эпох для ArcFace fine-tuning\n",
    "        self.arcface_s = 32.0  # Scale parameter\n",
    "        self.arcface_m = 0.5   # Margin parameter\n",
    "        self.arcface_easy_margin = True\n",
    "\n",
    "# ==================== ОБРАБОТКА ДАННЫХ ====================\n",
    "class CelebADataProcessor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.identity_df = config.identity_df\n",
    "\n",
    "        print(f\"Всего данных: {len(self.identity_df)} изображений\")\n",
    "        print(f\"Уникальных людей: {self.identity_df['person_id'].nunique()}\")\n",
    "\n",
    "    def filter_data(self):\n",
    "        person_counts = self.identity_df['person_id'].value_counts()\n",
    "        top_persons = person_counts.nlargest(self.config.max_classes).index\n",
    "        self.filtered_df = self.identity_df[self.identity_df['person_id'].isin(top_persons)].copy()\n",
    "\n",
    "        unique_ids = sorted(self.filtered_df['person_id'].unique())\n",
    "        self.id_to_idx = {old_id: idx for idx, old_id in enumerate(unique_ids)}\n",
    "        self.idx_to_id = {idx: old_id for old_id, idx in self.id_to_idx.items()}\n",
    "\n",
    "        self.filtered_df['class_idx'] = self.filtered_df['person_id'].map(self.id_to_idx)\n",
    "\n",
    "        print(f\"\\nПосле фильтрации:\")\n",
    "        print(f\"  Всего изображений: {len(self.filtered_df)}\")\n",
    "        print(f\"  Уникальных людей: {self.filtered_df['person_id'].nunique()}\")\n",
    "        print(f\"  Диапазон меток: {self.filtered_df['class_idx'].min()} - {self.filtered_df['class_idx'].max()}\")\n",
    "\n",
    "        return len(unique_ids)\n",
    "\n",
    "    def split_data_by_images(self):\n",
    "        print(f\"\\nРазделение данных по изображениям (стратифицировано)...\")\n",
    "\n",
    "        train_df, temp_df = train_test_split(\n",
    "            self.filtered_df,\n",
    "            test_size=self.config.val_ratio + self.config.test_ratio,\n",
    "            random_state=self.config.seed,\n",
    "            stratify=self.filtered_df['class_idx']\n",
    "        )\n",
    "\n",
    "        val_df, test_df = train_test_split(\n",
    "            temp_df,\n",
    "            test_size=self.config.test_ratio/(self.config.val_ratio + self.config.test_ratio),\n",
    "            random_state=self.config.seed,\n",
    "            stratify=temp_df['class_idx']\n",
    "        )\n",
    "\n",
    "        self.train_df = train_df.reset_index(drop=True)\n",
    "        self.val_df = val_df.reset_index(drop=True)\n",
    "        self.test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "        print(f\"Train: {len(self.train_df)} samples\")\n",
    "        print(f\"Val: {len(self.val_df)} samples\")\n",
    "        print(f\"Test: {len(self.test_df)} samples\")\n",
    "\n",
    "        return {\n",
    "            'train': len(self.train_df),\n",
    "            'val': len(self.val_df),\n",
    "            'test': len(self.test_df),\n",
    "            'num_persons': len(self.filtered_df['person_id'].unique())\n",
    "        }\n",
    "\n",
    "# ==================== ДАТАСЕТ ====================\n",
    "class CelebAClassificationDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = int(row['class_idx'])\n",
    "        return image, label\n",
    "\n",
    "# ==================== МОДЕЛИ ====================\n",
    "class SimpleFaceModel(nn.Module):\n",
    "    def __init__(self, num_classes=300, embedding_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "\n",
    "        # Заменяем последний слой\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Эмбеддинг слой (для совместимости с ArcFace)\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Классификатор\n",
    "        self.classifier = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "        # Замораживаем первые слои\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer1' in name or 'conv1' in name or 'bn1' in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        features = self.backbone(x)\n",
    "        embedding = self.embedding(features)\n",
    "        logits = self.classifier(embedding)\n",
    "\n",
    "        if labels is not None:\n",
    "            return logits, embedding\n",
    "        return logits, embedding\n",
    "\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    \"\"\"ArcFace loss слой\"\"\"\n",
    "    def __init__(self, in_features, out_features, s=32.0, m=0.3, easy_margin=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "        # Easy margin для стабильности\n",
    "        self.easy_margin = easy_margin\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "\n",
    "        # Инициализация весов\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "\n",
    "        # Предварительные вычисления\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # Угол для easy margin\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "        print(f\"ArcFace инициализирован: s={s}, m={m}\")\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # Нормализуем входные эмбеддинги\n",
    "        cosine = F.linear(F.normalize(input, p=2, dim=1),\n",
    "                         F.normalize(self.weight, p=2, dim=1))\n",
    "\n",
    "        # Обеспечиваем численную стабильность\n",
    "        cosine = cosine.clamp(-1 + 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Вычисляем синус\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2) + 1e-7)\n",
    "\n",
    "        # Косинус угла с маржой\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        # One-hot encoding меток\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "\n",
    "        # Комбинируем\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "class ArcFaceModel(nn.Module):\n",
    "    def __init__(self, num_classes=300, embedding_size=512, s=8.0, m=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Backbone (ResNet18)\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Embedding слой С BatchNorm\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # ArcFace слой\n",
    "        self.arcface = ArcMarginProduct(\n",
    "            embedding_size,\n",
    "            num_classes,\n",
    "            s=s,\n",
    "            m=m,\n",
    "            easy_margin=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\nArcFace Model создана:\")\n",
    "        print(f\"  Количество классов: {num_classes}\")\n",
    "        print(f\"  Embedding size: {embedding_size}\")\n",
    "        print(f\"  Scale s: {s}\")\n",
    "        print(f\"  Margin m: {m}\")\n",
    "\n",
    "    def load_from_ce_model(self, ce_model_path, device='cpu'):\n",
    "        \"\"\"Загрузка весов из CE модели\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"ЗАГРУЗКА ВЕСОВ ИЗ CE МОДЕЛИ\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        try:\n",
    "            # Загружаем CE модель\n",
    "            if os.path.exists(ce_model_path):\n",
    "                ce_checkpoint = torch.load(ce_model_path, map_location=device)\n",
    "\n",
    "                # Проверяем формат чекпоинта\n",
    "                if isinstance(ce_checkpoint, dict) and 'model_state_dict' in ce_checkpoint:\n",
    "                    ce_state_dict = ce_checkpoint['model_state_dict']\n",
    "                else:\n",
    "                    ce_state_dict = ce_checkpoint\n",
    "\n",
    "                # Загружаем веса в ArcFace модель\n",
    "                self_state_dict = self.state_dict()\n",
    "\n",
    "                # 1. Загружаем backbone (полное совпадение имен)\n",
    "                for name, param in self.backbone.named_parameters():\n",
    "                    ce_key = f'backbone.{name}'\n",
    "                    if ce_key in ce_state_dict:\n",
    "                        param.data.copy_(ce_state_dict[ce_key])\n",
    "\n",
    "                # 2. Загружаем embedding слой (полное совпадение имен)\n",
    "                for name, param in self.embedding.named_parameters():\n",
    "                    ce_key = f'embedding.{name}'\n",
    "                    if ce_key in ce_state_dict:\n",
    "                        param.data.copy_(ce_state_dict[ce_key])\n",
    "\n",
    "                # 3. Загружаем BatchNorm статистику\n",
    "                for name, buffer in self.embedding.named_buffers():\n",
    "                    ce_key = f'embedding.{name}'\n",
    "                    if ce_key in ce_state_dict:\n",
    "                        buffer.copy_(ce_state_dict[ce_key])\n",
    "\n",
    "                # 4. Инициализируем ArcFace слой из весов классификатора CE\n",
    "                if 'classifier.weight' in ce_state_dict:\n",
    "                    ce_weight = ce_state_dict['classifier.weight']\n",
    "\n",
    "                    # Нормализуем веса классификатора\n",
    "                    ce_weight_norm = F.normalize(ce_weight, p=2, dim=1)\n",
    "                    ce_weight_norm = ce_weight_norm * 0.1\n",
    "\n",
    "                    # Копируем в ArcFace слой\n",
    "                    self.arcface.weight.data.copy_(ce_weight_norm)\n",
    "\n",
    "                    print(f\"✓ Backbone загружен\")\n",
    "                    print(f\"✓ Embedding слой загружен\")\n",
    "                    print(f\"✓ ArcFace инициализирован из classifier.weight\")\n",
    "                    print(f\"✓ Scale s = {self.arcface.s}\")\n",
    "\n",
    "                    # Проверка размерностей\n",
    "                    print(f\"\\nПроверка размерностей:\")\n",
    "                    print(f\"  classifier.weight: {ce_weight.shape}\")\n",
    "                    print(f\"  arcface.weight: {self.arcface.weight.shape}\")\n",
    "                    print(f\"  Нормализованные веса: {ce_weight_norm.norm(dim=1).mean():.4f}\")\n",
    "\n",
    "                else:\n",
    "                    print(\"⚠ classifier.weight не найден, инициализируем ArcFace случайно\")\n",
    "                    self.arcface.s = 8.0  # Меньший scale\n",
    "\n",
    "            else:\n",
    "                print(f\"⚠ Файл {ce_model_path} не найден\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при загрузке: {e}\")\n",
    "            print(\"Обучаем ArcFace с нуля...\")\n",
    "            self.arcface.s = 16.0  # Меньший scale при обучении с нуля\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        # Извлекаем фичи\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # Получаем эмбеддинги\n",
    "        embeddings = self.embedding(features)\n",
    "\n",
    "        # Обязательно нормализуем для ArcFace\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels is not None:\n",
    "            # Для обучения: возвращаем logits и эмбеддинги\n",
    "            logits = self.arcface(embeddings, labels)\n",
    "            return logits, embeddings\n",
    "\n",
    "        # Для инференса: возвращаем только эмбеддинги\n",
    "        return embeddings\n",
    "\n",
    "# ==================== ФУНКЦИИ ОБУЧЕНИЯ ====================\n",
    "def train_epoch_ce(model, loader, optimizer, criterion, device):\n",
    "    \"\"\"Обучение CE модели для одной эпохи\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training CE\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = logits.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "        current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{current_acc:.1f}%'\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_epoch_arcface(model, loader, optimizer, criterion, device, epoch):\n",
    "    \"\"\"Обучение ArcFace модели для одной эпохи\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Progressive scaling\n",
    "    if epoch < 3:\n",
    "        model.arcface.s = 8.0\n",
    "    elif epoch < 6:\n",
    "        model.arcface.s = 16.0\n",
    "    elif epoch < 8:\n",
    "        model.arcface.s = 24.0\n",
    "    else:\n",
    "        model.arcface.s = 32.0\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training ArcFace (s={model.arcface.s:.1f})\")\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(images, labels)\n",
    "\n",
    "        if batch_idx == 0 and epoch == 0:\n",
    "            print(f\"\\n[DEBUG] Первый батч эпохи {epoch+1}:\")\n",
    "            print(f\"  Logits min/max: {logits.min():.4f}/{logits.max():.4f}\")\n",
    "            print(f\"  Logits mean/std: {logits.mean():.4f}/{logits.std():.4f}\")\n",
    "            print(f\"  Scale s: {model.arcface.s}\")\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Вычисляем accuracy (для ArcFace нужен softmax)\n",
    "        with torch.no_grad():\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            predicted = probs.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "            current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{current_acc:.1f}%'\n",
    "            })\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, model_type='ce'):\n",
    "    \"\"\"Валидация модели\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            if model_type == 'ce':\n",
    "                logits, _ = model(images)\n",
    "                _, predicted = logits.max(1)\n",
    "            else:  # arcface\n",
    "                logits, _ = model(images, labels)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                predicted = probs.argmax(dim=1)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total += images.size(0)\n",
    "\n",
    "    avg_loss = val_loss / val_total\n",
    "    accuracy = 100. * val_correct / val_total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    config = Config()\n",
    "\n",
    "    # ==================== 1. ПОДГОТОВКА ДАННЫХ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ПОДГОТОВКА ДАННЫХ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Копируем ваш работающий код подготовки данных\n",
    "    processor = CelebADataProcessor(config)\n",
    "    num_classes = processor.filter_data()\n",
    "    stats = processor.split_data_by_images()\n",
    "\n",
    "    # Трансформации (такие же как в работающем коде)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Датасеты\n",
    "    train_dataset = CelebAClassificationDataset(\n",
    "        processor.train_df, config.img_dir, train_transform\n",
    "    )\n",
    "    val_dataset = CelebAClassificationDataset(\n",
    "        processor.val_df, config.img_dir, val_transform\n",
    "    )\n",
    "    test_dataset = CelebAClassificationDataset(\n",
    "        processor.test_df, config.img_dir, val_transform\n",
    "    )\n",
    "\n",
    "    # Даталоадеры\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size,\n",
    "        shuffle=True, num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "\n",
    "    # Создаем папку для чекпоинтов\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "    # ==================== 2. ЗАГРУЗКА ОБУЧЕННОЙ CE МОДЕЛИ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ЗАГРУЗКА ОБУЧЕННОЙ CE МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Проверяем, есть ли уже обученная CE модель\n",
    "    ce_checkpoint_path = 'checkpoints/best_model_ce.pth'\n",
    "\n",
    "    if not os.path.exists(ce_checkpoint_path):\n",
    "        print(f\"Файл {ce_checkpoint_path} не найден\")\n",
    "        print(\"Обучаем CE модель сначала...\")\n",
    "\n",
    "        # Обучаем CE модель\n",
    "        model_ce = SimpleFaceModel(\n",
    "            num_classes=num_classes,\n",
    "            embedding_size=config.embedding_size\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer_ce = optim.Adam(\n",
    "            model_ce.parameters(),\n",
    "            lr=0.001,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "        scheduler_ce = optim.lr_scheduler.StepLR(optimizer_ce, step_size=10, gamma=0.5)\n",
    "        criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_ce_acc = 0\n",
    "        for epoch in range(config.num_epochs_ce):\n",
    "            print(f\"\\nEpoch {epoch+1}/{config.num_epochs_ce} (CE)\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            train_loss, train_acc = train_epoch_ce(\n",
    "                model_ce, train_loader, optimizer_ce, criterion_ce, device\n",
    "            )\n",
    "\n",
    "            val_loss, val_acc = validate(\n",
    "                model_ce, val_loader, criterion_ce, device, 'ce'\n",
    "            )\n",
    "\n",
    "            print(f\"\\nИтоги эпохи:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "            if val_acc > best_ce_acc:\n",
    "                best_ce_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model_ce.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'optimizer_state_dict': optimizer_ce.state_dict(),\n",
    "                }, ce_checkpoint_path)\n",
    "                print(f\"  ✓ Сохранена CE модель (Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "            scheduler_ce.step()\n",
    "\n",
    "    # ==================== 3. FINE-TUNING С ARCFACE ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINE-TUNING С ARCFACE LOSS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Создаем ArcFace модель\n",
    "    model_arcface = ArcFaceModel(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=config.embedding_size,\n",
    "        s=8.0,  # Начинаем с меньшего scale\n",
    "        m=config.arcface_m\n",
    "    ).to(device)\n",
    "\n",
    "    # Загружаем веса из CE модели\n",
    "    model_arcface.load_from_ce_model(ce_checkpoint_path, device)\n",
    "\n",
    "    # Проверка после загрузки\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ПРОВЕРКА ПОСЛЕ ЗАГРУЗКИ ВЕСОВ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    model_arcface.eval()\n",
    "    with torch.no_grad():\n",
    "        test_images, test_labels = next(iter(train_loader))\n",
    "        test_images = test_images[:4].to(device)\n",
    "        test_labels = test_labels[:4].to(device)\n",
    "\n",
    "        # Проверка forward pass\n",
    "        logits, embeddings = model_arcface(test_images, test_labels)\n",
    "\n",
    "        print(f\"\\n1. Проверка размерностей:\")\n",
    "        print(f\"   Logits shape: {logits.shape}\")\n",
    "        print(f\"   Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "        print(f\"\\n2. Проверка численных значений:\")\n",
    "        print(f\"   Logits range: [{logits.min():.4f}, {logits.max():.4f}]\")\n",
    "        print(f\"   Logits mean/std: {logits.mean():.4f} / {logits.std():.4f}\")\n",
    "\n",
    "        print(f\"\\n3. Проверка accuracy:\")\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        predicted = probs.argmax(dim=1)\n",
    "        accuracy = (predicted == test_labels).float().mean().item()\n",
    "        print(f\"   Accuracy на тестовом батче: {accuracy:.2%}\")\n",
    "\n",
    "        # Проверка потерь\n",
    "        test_loss = nn.CrossEntropyLoss()(logits, test_labels)\n",
    "        print(f\"   Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    # Оптимизатор для fine-tuning\n",
    "    optimizer_arc = optim.AdamW(\n",
    "        model_arcface.parameters(),\n",
    "        lr=config.learning_rate,  # Малый LR для fine-tuning\n",
    "        weight_decay=0.0005\n",
    "    )\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler_arc = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer_arc,\n",
    "        T_max=config.num_epochs_arcface,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    # Loss function с label smoothing\n",
    "    criterion_arc = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Обучение ArcFace\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"НАЧАЛО ОБУЧЕНИЯ ARCFACE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    best_arc_acc = 0\n",
    "    arc_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(config.num_epochs_arcface):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Epoch {epoch+1}/{config.num_epochs_arcface} - ArcFace Fine-tuning\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # Обучение\n",
    "        train_loss, train_acc = train_epoch_arcface(\n",
    "            model_arcface, train_loader, optimizer_arc, criterion_arc, device, epoch\n",
    "        )\n",
    "\n",
    "        # Валидация\n",
    "        val_loss, val_acc = validate(\n",
    "            model_arcface, val_loader, criterion_arc, device, 'arcface'\n",
    "        )\n",
    "\n",
    "        # Сохраняем историю\n",
    "        arc_history['loss'].append(train_loss)\n",
    "        arc_history['acc'].append(train_acc)\n",
    "        arc_history['val_loss'].append(val_loss)\n",
    "        arc_history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"\\n📊 Итоги эпохи:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  Scale s: {model_arcface.arcface.s}\")\n",
    "        print(f\"  Learning Rate: {optimizer_arc.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # Сохраняем лучшую модель\n",
    "        if val_acc > best_arc_acc:\n",
    "            best_arc_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_arcface.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_arc.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'scale': model_arcface.arcface.s,\n",
    "            }, 'checkpoints/best_model_arcface.pth')\n",
    "            print(f\"  💾 Сохранена лучшая ArcFace модель (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "        # Обновляем scheduler\n",
    "        scheduler_arc.step()\n",
    "\n",
    "    # ==================== 4. ТЕСТИРОВАНИЕ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ТЕСТИРОВАНИЕ ARCFACE МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Загружаем лучшую ArcFace модель\n",
    "    arc_checkpoint = torch.load('checkpoints/best_model_arcface.pth')\n",
    "    model_arcface.load_state_dict(arc_checkpoint['model_state_dict'])\n",
    "\n",
    "    # Тестирование\n",
    "    test_loss, test_acc = validate(\n",
    "        model_arcface, test_loader, criterion_arc, device, 'arcface'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n📊 Результаты ArcFace на тестовой выборке:\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Final Scale s: {model_arcface.arcface.s}\")\n",
    "\n",
    "    # ==================== 5. ВИЗУАЛИЗАЦИЯ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Создаем графики\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Loss history\n",
    "    axes[0, 0].plot(arc_history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(arc_history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('ArcFace: Loss History')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy history\n",
    "    axes[0, 1].plot(arc_history['acc'], label='Train Acc', linewidth=2)\n",
    "    axes[0, 1].plot(arc_history['val_acc'], label='Val Acc', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].set_title('ArcFace: Accuracy History')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning rate history\n",
    "    lr_history = [group['lr'] for group in optimizer_arc.param_groups]\n",
    "    axes[1, 0].plot(lr_history, linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Scale s history\n",
    "    scale_progression = [32, 32, 32, 48, 48, 48, 64, 64, 64, 64][:len(arc_history['loss'])]\n",
    "    axes[1, 1].plot(scale_progression, linewidth=2, color='green')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Scale s')\n",
    "    axes[1, 1].set_title('ArcFace Scale Progression')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('arcface_training_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ОБУЧЕНИЕ ARCFACE ЗАВЕРШЕНО!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Лучшая точность на валидации: {best_arc_acc:.2f}%\")\n",
    "    print(f\"Точность на тесте: {test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a3e0dde7cbc0768a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ЕЩЕ ОДИН ВАРИАНТ",
   "id": "f096573fc90613d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==================== КОНФИГУРАЦИЯ ====================\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Эти переменные должны быть определены в вашем окружении\n",
    "        # self.identity_df = df_id\n",
    "        # self.img_dir = img_dir\n",
    "        self.max_classes = 350\n",
    "        self.min_samples_per_person = 26\n",
    "        self.seed = 42\n",
    "        self.val_ratio = 0.15\n",
    "        self.test_ratio = 0.15\n",
    "        self.batch_size = 64\n",
    "        self.num_workers = 0\n",
    "        self.embedding_size = 512\n",
    "        self.learning_rate = 0.0001\n",
    "        self.num_epochs_ce = 15\n",
    "        self.num_epochs_arcface = 10\n",
    "        self.arcface_s = 32.0\n",
    "        self.arcface_m = 0.5\n",
    "        self.arcface_easy_margin = True\n",
    "\n",
    "# ==================== ОБРАБОТКА ДАННЫХ ====================\n",
    "class CelebADataProcessor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.identity_df = config.identity_df\n",
    "\n",
    "        print(f\"Всего данных: {len(self.identity_df)} изображений\")\n",
    "        print(f\"Уникальных людей: {self.identity_df['person_id'].nunique()}\")\n",
    "\n",
    "    def filter_data(self):\n",
    "        person_counts = self.identity_df['person_id'].value_counts()\n",
    "        top_persons = person_counts.nlargest(self.config.max_classes).index\n",
    "        self.filtered_df = self.identity_df[self.identity_df['person_id'].isin(top_persons)].copy()\n",
    "\n",
    "        unique_ids = sorted(self.filtered_df['person_id'].unique())\n",
    "        self.id_to_idx = {old_id: idx for idx, old_id in enumerate(unique_ids)}\n",
    "        self.idx_to_id = {idx: old_id for old_id, idx in self.id_to_idx.items()}\n",
    "\n",
    "        self.filtered_df['class_idx'] = self.filtered_df['person_id'].map(self.id_to_idx)\n",
    "\n",
    "        print(f\"\\nПосле фильтрации:\")\n",
    "        print(f\"  Всего изображений: {len(self.filtered_df)}\")\n",
    "        print(f\"  Уникальных людей: {self.filtered_df['person_id'].nunique()}\")\n",
    "        print(f\"  Диапазон меток: {self.filtered_df['class_idx'].min()} - {self.filtered_df['class_idx'].max()}\")\n",
    "\n",
    "        return len(unique_ids)\n",
    "\n",
    "    def split_data_by_images(self):\n",
    "        print(f\"\\nРазделение данных по изображениям (стратифицировано)...\")\n",
    "\n",
    "        train_df, temp_df = train_test_split(\n",
    "            self.filtered_df,\n",
    "            test_size=self.config.val_ratio + self.config.test_ratio,\n",
    "            random_state=self.config.seed,\n",
    "            stratify=self.filtered_df['class_idx']\n",
    "        )\n",
    "\n",
    "        val_df, test_df = train_test_split(\n",
    "            temp_df,\n",
    "            test_size=self.config.test_ratio/(self.config.val_ratio + self.config.test_ratio),\n",
    "            random_state=self.config.seed,\n",
    "            stratify=temp_df['class_idx']\n",
    "        )\n",
    "\n",
    "        self.train_df = train_df.reset_index(drop=True)\n",
    "        self.val_df = val_df.reset_index(drop=True)\n",
    "        self.test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "        print(f\"Train: {len(self.train_df)} samples\")\n",
    "        print(f\"Val: {len(self.val_df)} samples\")\n",
    "        print(f\"Test: {len(self.test_df)} samples\")\n",
    "\n",
    "        return {\n",
    "            'train': len(self.train_df),\n",
    "            'val': len(self.val_df),\n",
    "            'test': len(self.test_df),\n",
    "            'num_persons': len(self.filtered_df['person_id'].unique())\n",
    "        }\n",
    "\n",
    "# ==================== ДАТАСЕТ ====================\n",
    "class CelebAClassificationDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Настройка логирования\n",
    "        logging.basicConfig(\n",
    "            level=logging.WARNING,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            # Проверка валидности изображения\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "\n",
    "            # Проверка размера\n",
    "            if image.size[0] < 10 or image.size[1] < 10:\n",
    "                self.logger.warning(f\"Image {img_path} too small: {image.size}\")\n",
    "                image = image.resize((224, 224), Image.BILINEAR)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Cannot load image {img_path}: {e}\")\n",
    "            # Создаем черное изображение\n",
    "            image = Image.new('RGB', (224, 224), color=(0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = int(row['class_idx'])\n",
    "        return image, label\n",
    "\n",
    "# ==================== МОДЕЛИ ====================\n",
    "class SimpleFaceModel(nn.Module):\n",
    "    def __init__(self, num_classes=350, embedding_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "\n",
    "        # Заменяем последний слой\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Эмбеддинг слой\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Классификатор\n",
    "        self.classifier = nn.Linear(embedding_size, num_classes)\n",
    "\n",
    "        # Замораживаем первые слои\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer1' in name or 'conv1' in name or 'bn1' in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        embedding = self.embedding(features)\n",
    "        logits = self.classifier(embedding)\n",
    "        return logits, embedding\n",
    "\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    \"\"\"ArcFace loss слой\"\"\"\n",
    "    def __init__(self, in_features, out_features, s=32.0, m=0.5, easy_margin=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.easy_margin = easy_margin\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        # Предварительные вычисления\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # Угол для easy margin\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "        print(f\"ArcFace инициализирован: s={s}, m={m}\")\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # Нормализуем входные эмбеддинги\n",
    "        cosine = F.linear(F.normalize(input, p=2, dim=1),\n",
    "                         F.normalize(self.weight, p=2, dim=1))\n",
    "\n",
    "        # Обеспечиваем численную стабильность\n",
    "        cosine = cosine.clamp(-1 + 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Вычисляем синус\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2) + 1e-7)\n",
    "\n",
    "        # Косинус угла с маржой\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "\n",
    "        # One-hot encoding меток\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "\n",
    "        # Комбинируем\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "class ArcFaceModel(nn.Module):\n",
    "    def __init__(self, num_classes=350, embedding_size=512, s=8.0, m=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Backbone (ResNet18)\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # Embedding слой\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_size),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # ArcFace слой\n",
    "        self.arcface = ArcMarginProduct(\n",
    "            embedding_size,\n",
    "            num_classes,\n",
    "            s=s,\n",
    "            m=m,\n",
    "            easy_margin=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\nArcFace Model создана:\")\n",
    "        print(f\"  Количество классов: {num_classes}\")\n",
    "        print(f\"  Embedding size: {embedding_size}\")\n",
    "        print(f\"  Scale s: {s}\")\n",
    "        print(f\"  Margin m: {m}\")\n",
    "\n",
    "    def load_from_ce_model(self, ce_model_path, device='cpu'):\n",
    "        \"\"\"Загрузка весов из CE модели\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"ЗАГРУЗКА ВЕСОВ ИЗ CE МОДЕЛИ\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(ce_model_path):\n",
    "                print(f\"⚠ Файл {ce_model_path} не найден\")\n",
    "                print(\"Обучаем ArcFace с нуля...\")\n",
    "                self._initialize_random()\n",
    "                return False\n",
    "\n",
    "            # Загружаем CE модель\n",
    "            ce_checkpoint = torch.load(ce_model_path, map_location=device)\n",
    "\n",
    "            # Проверяем формат чекпоинта\n",
    "            if isinstance(ce_checkpoint, dict) and 'model_state_dict' in ce_checkpoint:\n",
    "                ce_state_dict = ce_checkpoint['model_state_dict']\n",
    "            else:\n",
    "                ce_state_dict = ce_checkpoint\n",
    "\n",
    "            # 1. Загружаем backbone\n",
    "            backbone_dict = {}\n",
    "            for key, value in ce_state_dict.items():\n",
    "                if key.startswith('backbone.'):\n",
    "                    # Убираем 'backbone.' из ключа\n",
    "                    new_key = key.replace('backbone.', '', 1)\n",
    "                    backbone_dict[new_key] = value\n",
    "\n",
    "            if backbone_dict:\n",
    "                missing_keys, unexpected_keys = self.backbone.load_state_dict(backbone_dict, strict=False)\n",
    "                print(\"✓ Backbone загружен\")\n",
    "                if missing_keys:\n",
    "                    print(f\"  Отсутствующие ключи: {missing_keys[:5]}{'...' if len(missing_keys) > 5 else ''}\")\n",
    "                if unexpected_keys:\n",
    "                    print(f\"  Неожиданные ключи: {unexpected_keys[:5]}{'...' if len(unexpected_keys) > 5 else ''}\")\n",
    "            else:\n",
    "                print(\"⚠ Backbone веса не найдены\")\n",
    "\n",
    "            # 2. Загружаем embedding слой\n",
    "            embedding_dict = {}\n",
    "            for key, value in ce_state_dict.items():\n",
    "                if key.startswith('embedding.'):\n",
    "                    new_key = key.replace('embedding.', '', 1)\n",
    "                    embedding_dict[new_key] = value\n",
    "\n",
    "            if embedding_dict:\n",
    "                self.embedding.load_state_dict(embedding_dict, strict=False)\n",
    "                print(\"✓ Embedding слой загружен\")\n",
    "            else:\n",
    "                print(\"⚠ Embedding веса не найдены\")\n",
    "\n",
    "            # 3. Инициализируем ArcFace слой\n",
    "            self._initialize_arcface()\n",
    "            print(\"✓ ArcFace инициализирован случайно\")\n",
    "            print(f\"✓ Scale s = {self.arcface.s}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при загрузке: {e}\")\n",
    "            print(\"Обучаем ArcFace с нуля...\")\n",
    "            self._initialize_random()\n",
    "            return False\n",
    "\n",
    "    def _initialize_arcface(self):\n",
    "        \"\"\"Инициализация ArcFace слоя\"\"\"\n",
    "        nn.init.xavier_uniform_(self.arcface.weight)\n",
    "        self.arcface.s = 8.0\n",
    "\n",
    "    def _initialize_random(self):\n",
    "        \"\"\"Полная случайная инициализация\"\"\"\n",
    "        for module in [self.embedding, self.arcface]:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.zeros_(m.bias)\n",
    "                elif isinstance(m, nn.BatchNorm1d):\n",
    "                    nn.init.ones_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "        self.arcface.s = 8.0\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        # Извлекаем фичи\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # Получаем эмбеддинги\n",
    "        embeddings = self.embedding(features)\n",
    "\n",
    "        # Нормализуем для ArcFace (важно!)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "        if labels is not None:\n",
    "            # Для обучения: возвращаем logits и эмбеддинги\n",
    "            logits = self.arcface(embeddings, labels)\n",
    "            return logits, embeddings\n",
    "\n",
    "        # Для инференса: возвращаем только эмбеддинги\n",
    "        return embeddings\n",
    "\n",
    "# ==================== УТИЛИТЫ ДЛЯ ВАЛИДАЦИИ ====================\n",
    "def analyze_embeddings(model, loader, device, num_samples=1000):\n",
    "    \"\"\"Анализ качества эмбеддингов\"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\nАнализ качества эмбеддингов...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(tqdm(loader, desc=\"Extracting embeddings\")):\n",
    "            if i * loader.batch_size >= num_samples:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            embeddings = model(images)  # Эмбеддинги уже нормализованы\n",
    "\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    if not all_embeddings:\n",
    "        return None, None\n",
    "\n",
    "    all_embeddings = torch.cat(all_embeddings)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Берем подвыборку для анализа\n",
    "    if len(all_embeddings) > 5000:\n",
    "        indices = torch.randperm(len(all_embeddings))[:5000]\n",
    "        all_embeddings = all_embeddings[indices]\n",
    "        all_labels = all_labels[indices]\n",
    "\n",
    "    # Вычисляем косинусные расстояния\n",
    "    embeddings_norm = all_embeddings  # Уже нормализованы\n",
    "    cosine_sim = torch.mm(embeddings_norm, embeddings_norm.t())\n",
    "\n",
    "    # Анализ внутриклассовых и межклассовых расстояний\n",
    "    intra_distances = []\n",
    "    inter_distances = []\n",
    "\n",
    "    unique_labels = torch.unique(all_labels)\n",
    "\n",
    "    for i, label_i in enumerate(unique_labels[:20]):  # Ограничим для скорости\n",
    "        mask_i = (all_labels == label_i)\n",
    "        indices_i = torch.where(mask_i)[0]\n",
    "\n",
    "        if len(indices_i) > 1:\n",
    "            # Внутри класса\n",
    "            for j in range(min(len(indices_i), 5)):  # Берем несколько пар\n",
    "                for k in range(j+1, min(len(indices_i), 5)):\n",
    "                    sim = cosine_sim[indices_i[j], indices_i[k]].item()\n",
    "                    intra_distances.append(sim)\n",
    "\n",
    "        # Между классами (берем первый другой класс)\n",
    "        if i < len(unique_labels) - 1:\n",
    "            label_j = unique_labels[i+1]\n",
    "            mask_j = (all_labels == label_j)\n",
    "            indices_j = torch.where(mask_j)[0]\n",
    "\n",
    "            if len(indices_j) > 0:\n",
    "                # Берем несколько пар между классами\n",
    "                for _ in range(min(5, len(indices_i))):\n",
    "                    idx_i = indices_i[torch.randint(0, len(indices_i), (1,))]\n",
    "                    idx_j = indices_j[torch.randint(0, len(indices_j), (1,))]\n",
    "                    sim = cosine_sim[idx_i, idx_j].item()\n",
    "                    inter_distances.append(sim)\n",
    "\n",
    "    if intra_distances and inter_distances:\n",
    "        intra_mean = np.mean(intra_distances)\n",
    "        inter_mean = np.mean(inter_distances)\n",
    "\n",
    "        print(f\"\\n📊 Качество эмбеддингов:\")\n",
    "        print(f\"  Средняя косинусная схожесть внутри класса: {intra_mean:.4f}\")\n",
    "        print(f\"  Средняя косинусная схожесть между классами: {inter_mean:.4f}\")\n",
    "        print(f\"  Ratio (inter/intra): {inter_mean/intra_mean if intra_mean > 0 else float('inf'):.2f}\")\n",
    "\n",
    "        # Создаем гистограмму расстояний\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # Гистограмма внутриклассовых расстояний\n",
    "        axes[0].hist(intra_distances, bins=30, alpha=0.7, color='blue', density=True)\n",
    "        axes[0].axvline(x=intra_mean, color='red', linestyle='--', label=f'Mean: {intra_mean:.3f}')\n",
    "        axes[0].set_xlabel('Cosine Similarity (Intra-class)')\n",
    "        axes[0].set_ylabel('Density')\n",
    "        axes[0].set_title('Intra-class Similarity Distribution')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "        # Гистограмма межклассовых расстояний\n",
    "        axes[1].hist(inter_distances, bins=30, alpha=0.7, color='green', density=True)\n",
    "        axes[1].axvline(x=inter_mean, color='red', linestyle='--', label=f'Mean: {inter_mean:.3f}')\n",
    "        axes[1].set_xlabel('Cosine Similarity (Inter-class)')\n",
    "        axes[1].set_ylabel('Density')\n",
    "        axes[1].set_title('Inter-class Similarity Distribution')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('embedding_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    return all_embeddings, all_labels\n",
    "\n",
    "# ==================== ФУНКЦИИ ОБУЧЕНИЯ ====================\n",
    "def train_epoch_ce(model, loader, optimizer, criterion, device):\n",
    "    \"\"\"Обучение CE модели для одной эпохи\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training CE\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = logits.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "        current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{current_acc:.1f}%'\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def train_epoch_arcface(model, loader, optimizer, criterion, device, epoch, total_epochs):\n",
    "    \"\"\"Обучение ArcFace модели для одной эпохи\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Progressive scaling - более плавное увеличение\n",
    "    min_scale, max_scale = 8.0, 32.0\n",
    "    if total_epochs <= 1:\n",
    "        current_scale = max_scale\n",
    "    else:\n",
    "        progress = epoch / (total_epochs - 1)\n",
    "        # Используем квадратичное увеличение\n",
    "        current_scale = min_scale + (max_scale - min_scale) * (progress ** 0.5)\n",
    "\n",
    "    model.arcface.s = current_scale\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training ArcFace (s={model.arcface.s:.1f}, m={model.arcface.m:.2f})\")\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, embeddings = model(images, labels)\n",
    "\n",
    "        # DEBUG информация\n",
    "        if batch_idx == 0 and epoch == 0:\n",
    "            print(f\"\\n[DEBUG] Первый батч:\")\n",
    "            print(f\"  Logits shape: {logits.shape}\")\n",
    "            print(f\"  Logits range: [{logits.min():.4f}, {logits.max():.4f}]\")\n",
    "            print(f\"  Logits mean/std: {logits.mean():.4f}/{logits.std():.4f}\")\n",
    "            print(f\"  Embeddings norm: {embeddings.norm(p=2, dim=1).mean():.4f} ± {embeddings.norm(p=2, dim=1).std():.4f}\")\n",
    "            print(f\"  Scale s: {model.arcface.s}\")\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Вычисляем accuracy\n",
    "        with torch.no_grad():\n",
    "            # Для ArcFace используем cosine similarity\n",
    "            embeddings_norm = embeddings  # Уже нормализованы\n",
    "            weights_norm = F.normalize(model.arcface.weight.data, p=2, dim=1)\n",
    "            cosine = torch.mm(embeddings_norm, weights_norm.t())\n",
    "            predicted = cosine.argmax(dim=1)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "            current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{current_acc:.1f}%',\n",
    "                'scale': f'{model.arcface.s:.1f}'\n",
    "            })\n",
    "\n",
    "    avg_loss = total_loss / total if total > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(model, loader, criterion, device, model_type='ce'):\n",
    "    \"\"\"Валидация модели\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validation\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            if model_type == 'ce':\n",
    "                logits, _ = model(images)\n",
    "                _, predicted = logits.max(1)\n",
    "            else:  # arcface\n",
    "                embeddings = model(images)\n",
    "                embeddings_norm = embeddings  # Уже нормализованы\n",
    "                weights_norm = F.normalize(model.arcface.weight.data, p=2, dim=1)\n",
    "                cosine = torch.mm(embeddings_norm, weights_norm.t())\n",
    "                logits = model.arcface.s * cosine\n",
    "                predicted = cosine.argmax(dim=1)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total += images.size(0)\n",
    "\n",
    "            current_acc = 100. * predicted.eq(labels).sum().item() / images.size(0)\n",
    "            pbar.set_postfix({'acc': f'{current_acc:.1f}%'})\n",
    "\n",
    "    avg_loss = val_loss / val_total if val_total > 0 else 0\n",
    "    accuracy = 100. * val_correct / val_total if val_total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# ==================== ОСНОВНАЯ ФУНКЦИЯ ====================\n",
    "def main():\n",
    "    # Настройка логирования\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(f'training_{timestamp}.log'),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "    # Инициализация конфигурации\n",
    "    config = Config()\n",
    "\n",
    "    # ==================== 1. ПОДГОТОВКА ДАННЫХ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ПОДГОТОВКА ДАННЫХ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Здесь нужно загрузить ваши данные\n",
    "    # config.identity_df = df_id  # ваш DataFrame\n",
    "    # config.img_dir = img_dir    # путь к изображениям\n",
    "\n",
    "    if not hasattr(config, 'identity_df') or config.identity_df is None:\n",
    "        print(\"❌ Ошибка: identity_df не задан в конфигурации\")\n",
    "        print(\"Установите config.identity_df = ваш_dataframe\")\n",
    "        return\n",
    "\n",
    "    if not hasattr(config, 'img_dir') or config.img_dir is None:\n",
    "        print(\"❌ Ошибка: img_dir не задан в конфигурации\")\n",
    "        print(\"Установите config.img_dir = 'путь/к/изображениям'\")\n",
    "        return\n",
    "\n",
    "    processor = CelebADataProcessor(config)\n",
    "    num_classes = processor.filter_data()\n",
    "    stats = processor.split_data_by_images()\n",
    "\n",
    "    # Трансформации\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Датасеты\n",
    "    train_dataset = CelebAClassificationDataset(\n",
    "        processor.train_df, config.img_dir, train_transform\n",
    "    )\n",
    "    val_dataset = CelebAClassificationDataset(\n",
    "        processor.val_df, config.img_dir, val_transform\n",
    "    )\n",
    "    test_dataset = CelebAClassificationDataset(\n",
    "        processor.test_df, config.img_dir, val_transform\n",
    "    )\n",
    "\n",
    "    # Даталоадеры\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size,\n",
    "        shuffle=True, num_workers=config.num_workers,\n",
    "        pin_memory=True, drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size,\n",
    "        shuffle=False, num_workers=config.num_workers\n",
    "    )\n",
    "\n",
    "    # Создаем папку для чекпоинтов\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "    # ==================== 2. ОБУЧЕНИЕ CE МОДЕЛИ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ОБУЧЕНИЕ CE МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    ce_checkpoint_path = 'checkpoints/best_model_ce.pth'\n",
    "    ce_model_exists = os.path.exists(ce_checkpoint_path)\n",
    "\n",
    "    if not ce_model_exists:\n",
    "        print(\"Обучение CE модели с нуля...\")\n",
    "\n",
    "        model_ce = SimpleFaceModel(\n",
    "            num_classes=num_classes,\n",
    "            embedding_size=config.embedding_size\n",
    "        ).to(device)\n",
    "\n",
    "        # Размораживаем больше слоев\n",
    "        for param in model_ce.backbone.layer2.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model_ce.backbone.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        optimizer_ce = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model_ce.parameters()),\n",
    "            lr=0.001,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "        scheduler_ce = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer_ce,\n",
    "            T_max=config.num_epochs_ce,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "\n",
    "        criterion_ce = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        best_ce_acc = 0\n",
    "        ce_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "        for epoch in range(config.num_epochs_ce):\n",
    "            print(f\"\\nEpoch {epoch+1}/{config.num_epochs_ce} (CE)\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            train_loss, train_acc = train_epoch_ce(\n",
    "                model_ce, train_loader, optimizer_ce, criterion_ce, device\n",
    "            )\n",
    "\n",
    "            val_loss, val_acc = validate(\n",
    "                model_ce, val_loader, criterion_ce, device, 'ce'\n",
    "            )\n",
    "\n",
    "            # Сохраняем историю\n",
    "            ce_history['loss'].append(train_loss)\n",
    "            ce_history['acc'].append(train_acc)\n",
    "            ce_history['val_loss'].append(val_loss)\n",
    "            ce_history['val_acc'].append(val_acc)\n",
    "\n",
    "            print(f\"\\nИтоги эпохи:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            print(f\"  Learning Rate: {optimizer_ce.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            if val_acc > best_ce_acc:\n",
    "                best_ce_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model_ce.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'optimizer_state_dict': optimizer_ce.state_dict(),\n",
    "                    'history': ce_history,\n",
    "                    'num_classes': num_classes\n",
    "                }, ce_checkpoint_path)\n",
    "                print(f\"  ✓ Сохранена CE модель (Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "            scheduler_ce.step()\n",
    "\n",
    "        print(f\"\\n🎯 Лучшая точность CE модели: {best_ce_acc:.2f}%\")\n",
    "    else:\n",
    "        print(f\"✅ CE модель уже обучена: {ce_checkpoint_path}\")\n",
    "\n",
    "    # ==================== 3. FINE-TUNING С ARCFACE ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINE-TUNING С ARCFACE LOSS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Создаем ArcFace модель\n",
    "    model_arcface = ArcFaceModel(\n",
    "        num_classes=num_classes,\n",
    "        embedding_size=config.embedding_size,\n",
    "        s=8.0,  # Начинаем с меньшего scale\n",
    "        m=config.arcface_m\n",
    "    ).to(device)\n",
    "\n",
    "    # Загружаем веса из CE модели\n",
    "    print(\"\\nЗагрузка весов из CE модели...\")\n",
    "    load_success = model_arcface.load_from_ce_model(ce_checkpoint_path, device)\n",
    "\n",
    "    # Размораживаем все слои для fine-tuning\n",
    "    for param in model_arcface.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Проверка модели\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ПРОВЕРКА МОДЕЛИ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    model_arcface.eval()\n",
    "    with torch.no_grad():\n",
    "        test_images, test_labels = next(iter(train_loader))\n",
    "        test_images = test_images[:4].to(device)\n",
    "        test_labels = test_labels[:4].to(device)\n",
    "\n",
    "        logits, embeddings = model_arcface(test_images, test_labels)\n",
    "\n",
    "        print(f\"\\n1. Размерности:\")\n",
    "        print(f\"   Logits shape: {logits.shape}\")\n",
    "        print(f\"   Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "        print(f\"\\n2. Численные значения:\")\n",
    "        print(f\"   Logits range: [{logits.min():.4f}, {logits.max():.4f}]\")\n",
    "        print(f\"   Logits mean/std: {logits.mean():.4f} / {logits.std():.4f}\")\n",
    "        print(f\"   Embeddings norm: {embeddings.norm(p=2, dim=1).mean():.4f} ± {embeddings.norm(p=2, dim=1).std():.4f}\")\n",
    "\n",
    "        print(f\"\\n3. Проверка accuracy:\")\n",
    "        embeddings_norm = embeddings  # Уже нормализованы\n",
    "        weights_norm = F.normalize(model_arcface.arcface.weight.data, p=2, dim=1)\n",
    "        cosine = torch.mm(embeddings_norm, weights_norm.t())\n",
    "        predicted = cosine.argmax(dim=1)\n",
    "        accuracy = (predicted == test_labels).float().mean().item()\n",
    "        print(f\"   Accuracy на тестовом батче: {accuracy:.2%}\")\n",
    "\n",
    "        test_loss = nn.CrossEntropyLoss()(logits, test_labels)\n",
    "        print(f\"   Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "    # Оптимизатор для fine-tuning\n",
    "    optimizer_arc = optim.AdamW(\n",
    "        model_arcface.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=0.0005\n",
    "    )\n",
    "\n",
    "    # Scheduler с warmup\n",
    "    scheduler_arc = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer_arc,\n",
    "        max_lr=config.learning_rate * 10,\n",
    "        epochs=config.num_epochs_arcface,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3\n",
    "    )\n",
    "\n",
    "    # Loss function с label smoothing\n",
    "    criterion_arc = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # Обучение ArcFace\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"НАЧАЛО ОБУЧЕНИЯ ARCFACE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    best_arc_acc = 0\n",
    "    arc_history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': [], 'scale': []}\n",
    "\n",
    "    for epoch in range(config.num_epochs_arcface):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Epoch {epoch+1}/{config.num_epochs_arcface} - ArcFace Fine-tuning\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # Обучение\n",
    "        train_loss, train_acc = train_epoch_arcface(\n",
    "            model_arcface, train_loader, optimizer_arc, criterion_arc, device,\n",
    "            epoch, config.num_epochs_arcface\n",
    "        )\n",
    "\n",
    "        # Валидация\n",
    "        val_loss, val_acc = validate(\n",
    "            model_arcface, val_loader, criterion_arc, device, 'arcface'\n",
    "        )\n",
    "\n",
    "        # Сохраняем историю\n",
    "        arc_history['loss'].append(train_loss)\n",
    "        arc_history['acc'].append(train_acc)\n",
    "        arc_history['val_loss'].append(val_loss)\n",
    "        arc_history['val_acc'].append(val_acc)\n",
    "        arc_history['scale'].append(model_arcface.arcface.s)\n",
    "\n",
    "        print(f\"\\n📊 Итоги эпохи:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  Scale s: {model_arcface.arcface.s:.1f}\")\n",
    "        print(f\"  Margin m: {model_arcface.arcface.m:.2f}\")\n",
    "        print(f\"  Learning Rate: {optimizer_arc.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        # Сохраняем лучшую модель\n",
    "        if val_acc > best_arc_acc:\n",
    "            best_arc_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model_arcface.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_arc.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'scale': model_arcface.arcface.s,\n",
    "                'margin': model_arcface.arcface.m,\n",
    "                'history': arc_history,\n",
    "                'num_classes': num_classes\n",
    "            }, 'checkpoints/best_model_arcface.pth')\n",
    "            print(f\"  💾 Сохранена лучшая ArcFace модель (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "        # Обновляем scheduler\n",
    "        scheduler_arc.step()\n",
    "\n",
    "    # ==================== 4. ТЕСТИРОВАНИЕ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ТЕСТИРОВАНИЕ ARCFACE МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Загружаем лучшую ArcFace модель\n",
    "    arc_checkpoint_path = 'checkpoints/best_model_arcface.pth'\n",
    "    if os.path.exists(arc_checkpoint_path):\n",
    "        arc_checkpoint = torch.load(arc_checkpoint_path, map_location=device)\n",
    "        model_arcface.load_state_dict(arc_checkpoint['model_state_dict'])\n",
    "        print(f\"✅ Загружена лучшая ArcFace модель (Val Acc: {arc_checkpoint['val_acc']:.2f}%)\")\n",
    "    else:\n",
    "        print(\"⚠ Лучшая модель не найдена, используем последнюю\")\n",
    "\n",
    "    # Тестирование\n",
    "    test_loss, test_acc = validate(\n",
    "        model_arcface, test_loader, criterion_arc, device, 'arcface'\n",
    "    )\n",
    "\n",
    "    print(f\"\\n🎯 РЕЗУЛЬТАТЫ ARCFACE НА ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Final Scale s: {model_arcface.arcface.s:.1f}\")\n",
    "    print(f\"  Final Margin m: {model_arcface.arcface.m:.2f}\")\n",
    "\n",
    "    # Анализ эмбеддингов\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"АНАЛИЗ КАЧЕСТВА ЭМБЕДДИНГОВ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    test_embeddings, test_labels = analyze_embeddings(\n",
    "        model_arcface, test_loader, device, num_samples=2000\n",
    "    )\n",
    "\n",
    "    # ==================== 5. ВИЗУАЛИЗАЦИЯ ====================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ ОБУЧЕНИЯ\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Создаем графики\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Loss history\n",
    "    axes[0, 0].plot(arc_history['loss'], label='Train Loss', linewidth=2, marker='o', markersize=4)\n",
    "    axes[0, 0].plot(arc_history['val_loss'], label='Val Loss', linewidth=2, marker='s', markersize=4)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('ArcFace: Loss History')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy history\n",
    "    axes[0, 1].plot(arc_history['acc'], label='Train Acc', linewidth=2, marker='o', markersize=4)\n",
    "    axes[0, 1].plot(arc_history['val_acc'], label='Val Acc', linewidth=2, marker='s', markersize=4)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].set_title('ArcFace: Accuracy History')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim([0, 100])\n",
    "\n",
    "    # Scale s history\n",
    "    axes[1, 0].plot(arc_history['scale'], linewidth=2, marker='o', markersize=4, color='green')\n",
    "    axes[1, 0].fill_between(range(len(arc_history['scale'])),\n",
    "                           arc_history['scale'],\n",
    "                           alpha=0.3, color='green')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Scale s')\n",
    "    axes[1, 0].set_title('ArcFace Scale Progression')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning rate history (симулируем)\n",
    "    lr_values = []\n",
    "    temp_optimizer = optim.AdamW([torch.zeros(1)], lr=config.learning_rate)\n",
    "    temp_scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        temp_optimizer,\n",
    "        max_lr=config.learning_rate * 10,\n",
    "        epochs=config.num_epochs_arcface,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3\n",
    "    )\n",
    "\n",
    "    for epoch in range(config.num_epochs_arcface):\n",
    "        for _ in range(len(train_loader)):\n",
    "            lr_values.append(temp_optimizer.param_groups[0]['lr'])\n",
    "            temp_scheduler.step()\n",
    "\n",
    "    # Берем значения на начало каждой эпохи\n",
    "    epoch_lr = [lr_values[i * len(train_loader)] for i in range(config.num_epochs_arcface)]\n",
    "\n",
    "    axes[1, 1].plot(epoch_lr, linewidth=2, marker='o', markersize=4, color='orange')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Learning Rate')\n",
    "    axes[1, 1].set_title('Learning Rate Schedule (OneCycle)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'arcface_training_results_{timestamp}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 ОБУЧЕНИЕ ARCFACE ЗАВЕРШЕНО!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"📊 Итоговые результаты:\")\n",
    "    print(f\"  Лучшая точность на валидации: {best_arc_acc:.2f}%\")\n",
    "    print(f\"  Точность на тесте: {test_acc:.2f}%\")\n",
    "    print(f\"  Финальный Scale s: {model_arcface.arcface.s:.1f}\")\n",
    "    print(f\"  Финальный Margin m: {model_arcface.arcface.m:.2f}\")\n",
    "    print(f\"\\n💾 Файлы сохранены:\")\n",
    "    print(f\"  Чекпоинты: 'checkpoints/'\")\n",
    "    print(f\"  Лог: 'training_{timestamp}.log'\")\n",
    "    print(f\"  Графики: 'arcface_training_results_{timestamp}.png'\")\n",
    "    print(f\"  Анализ эмбеддингов: 'embedding_analysis.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "23044b430d9f8761"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
